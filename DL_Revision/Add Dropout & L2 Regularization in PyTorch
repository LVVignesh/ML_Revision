# =========================================================
# PYTORCH NN WITH DROPOUT + L2 REGULARIZATION
# ONLINE SHOPPERS DATASET
# =========================================================

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# =========================================================
# STEP 1: LOAD & PREPROCESS DATA
# =========================================================

df = pd.read_csv("online_shoppers_intention.csv")
df["Revenue"] = df["Revenue"].astype(int)

df = pd.get_dummies(df, drop_first=True)

X = df.drop("Revenue", axis=1).values
y = df["Revenue"].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# =========================================================
# STEP 2: DATASET + DATALOADER
# =========================================================

class ShopperDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_loader = DataLoader(
    ShopperDataset(X_train, y_train),
    batch_size=32,
    shuffle=True
)

test_loader = DataLoader(
    ShopperDataset(X_test, y_test),
    batch_size=32,
    shuffle=False
)

# =========================================================
# STEP 3: MODEL WITH DROPOUT
# =========================================================

class ShopperNN(nn.Module):
    def __init__(self, input_size):
        super().__init__()

        self.net = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(p=0.3),          # ðŸ”¥ Dropout

            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(p=0.3),          # ðŸ”¥ Dropout

            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)

model = ShopperNN(X_train.shape[1])

# =========================================================
# STEP 4: LOSS + OPTIMIZER (WITH L2)
# =========================================================

criterion = nn.BCELoss()

optimizer = optim.Adam(
    model.parameters(),
    lr=0.001,
    weight_decay=0.0001   # ðŸ”¥ L2 REGULARIZATION
)

# =========================================================
# STEP 5: TRAINING LOOP
# =========================================================

epochs = 50

for epoch in range(epochs):

    model.train()
    total_loss = 0

    for X_batch, y_batch in train_loader:

        optimizer.zero_grad()

        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    if epoch % 10 == 0:
        print(f"Epoch {epoch} | Avg Loss: {total_loss / len(train_loader):.4f}")

# =========================================================
# STEP 6: EVALUATION
# =========================================================

model.eval()
correct = 0
total = 0

with torch.no_grad():
    for X_batch, y_batch in test_loader:
        outputs = model(X_batch)
        preds = (outputs >= 0.5).float()
        correct += (preds == y_batch).sum().item()
        total += y_batch.size(0)

print("\nTEST ACCURACY:", correct / total)
